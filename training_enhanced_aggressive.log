/content/HRM_PyTorch_loc_pred/src/hrm/modeling/hrm_enhanced.py:425: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  hour = (start_min // 60) % 24
No module named 'torch_sparse'
`torch-sparse` is not installed, which is ok, as long as no sparse modules are used.
Using device: cuda
GPU: NVIDIA L4

============================================================
Loading datasets...
============================================================
Loaded 7424 samples from data/geolife/geolife_transformer_7_train.pk
Vocabulary size: 1187 (unique locations: 1156)
Loaded 3334 samples from data/geolife/geolife_transformer_7_validation.pk
Vocabulary size: 1176 (unique locations: 382)
Loaded 3502 samples from data/geolife/geolife_transformer_7_test.pk
Vocabulary size: 1177 (unique locations: 355)
Train samples: 7424
Val samples: 3334
Test samples: 3502

============================================================
Initializing Enhanced HRM...
============================================================
Total parameters: 440,669
Trainable parameters: 440,669
Target: <500K parameters
✓ Within budget!
EMA decay: 0.999
Temporal jittering: enabled
Adaptive gradient accumulation: enabled
Loss: Adaptive TopKCrossEntropyLoss

============================================================
Starting training with advanced techniques...
============================================================


============================================================
Epoch 1/600
============================================================
Epoch 1 | Batch 10/78 | Loss: 3.3802 (TopK: 3.3765, CE: 7.0820) | Acc@1: 0.0000 | Acc@5: 0.0000 | Acc@10: 0.0000 | AccumSteps: 1
Epoch 1 | Batch 20/78 | Loss: 3.3710 (TopK: 3.3673, CE: 7.0818) | Acc@1: 0.0000 | Acc@5: 0.0000 | Acc@10: 0.0000 | AccumSteps: 1
Epoch 1 | Batch 30/78 | Loss: 3.3584 (TopK: 3.3546, CE: 7.0775) | Acc@1: 0.0000 | Acc@5: 0.0000 | Acc@10: 0.0104 | AccumSteps: 1
Epoch 1 | Batch 40/78 | Loss: 3.3523 (TopK: 3.3486, CE: 7.0752) | Acc@1: 0.1146 | Acc@5: 0.1979 | Acc@10: 0.2292 | AccumSteps: 1
Epoch 1 | Batch 50/78 | Loss: 3.3525 (TopK: 3.3487, CE: 7.0762) | Acc@1: 0.0625 | Acc@5: 0.1250 | Acc@10: 0.1354 | AccumSteps: 1
Epoch 1 | Batch 60/78 | Loss: 3.3512 (TopK: 3.3475, CE: 7.0752) | Acc@1: 0.0417 | Acc@5: 0.1458 | Acc@10: 0.1771 | AccumSteps: 1
Epoch 1 | Batch 70/78 | Loss: 3.3503 (TopK: 3.3466, CE: 7.0743) | Acc@1: 0.1042 | Acc@5: 0.1875 | Acc@10: 0.2083 | AccumSteps: 1

Validation Results:
  Loss: 7.0847
  Acc@1: 0.0000 (0.00%)
  Acc@5: 0.0003 (0.03%)
  Acc@10: 0.0006 (0.06%)


Test Results:
  Loss: 7.0831
  Acc@1: 0.0003 (0.03%)
  Acc@5: 0.0003 (0.03%)
  Acc@10: 0.0011 (0.11%)

Epoch 1 Summary:
  Train - Loss: 3.3603 (TopK: 3.3566[1.00], CE: 7.0775) | Acc@1: 0.0467
  Val   - Loss: 7.0847 | Acc@1: 0.0000
  Test  - Loss: 7.0831 | Acc@1: 0.0003
  Time: 13.93s | LR: 0.000133
  Params: 440,669
  ✅ New best test accuracy! (0.03%)

============================================================
Epoch 2/600
============================================================
Epoch 2 | Batch 10/78 | Loss: 3.3526 (TopK: 3.3451, CE: 7.0731) | Acc@1: 0.0833 | Acc@5: 0.2188 | Acc@10: 0.2604 | AccumSteps: 1
Epoch 2 | Batch 20/78 | Loss: 3.3504 (TopK: 3.3429, CE: 7.0703) | Acc@1: 0.0938 | Acc@5: 0.2812 | Acc@10: 0.3854 | AccumSteps: 1
Epoch 2 | Batch 30/78 | Loss: 3.3490 (TopK: 3.3415, CE: 7.0672) | Acc@1: 0.1562 | Acc@5: 0.2812 | Acc@10: 0.3229 | AccumSteps: 1
Epoch 2 | Batch 40/78 | Loss: 3.3440 (TopK: 3.3365, CE: 7.0543) | Acc@1: 0.1667 | Acc@5: 0.3021 | Acc@10: 0.3438 | AccumSteps: 1
Epoch 2 | Batch 50/78 | Loss: 3.3074 (TopK: 3.3000, CE: 7.0005) | Acc@1: 0.2500 | Acc@5: 0.4167 | Acc@10: 0.4479 | AccumSteps: 1
Epoch 2 | Batch 60/78 | Loss: 3.2027 (TopK: 3.1954, CE: 6.8407) | Acc@1: 0.2083 | Acc@5: 0.3438 | Acc@10: 0.3646 | AccumSteps: 1
Epoch 2 | Batch 70/78 | Loss: 2.9672 (TopK: 2.9601, CE: 6.5202) | Acc@1: 0.2396 | Acc@5: 0.4271 | Acc@10: 0.5000 | AccumSteps: 1

Validation Results:
  Loss: 7.0826
  Acc@1: 0.0000 (0.00%)
  Acc@5: 0.0003 (0.03%)
  Acc@10: 0.0009 (0.09%)


Test Results:
  Loss: 7.0815
  Acc@1: 0.0003 (0.03%)
  Acc@5: 0.0006 (0.06%)
  Acc@10: 0.0011 (0.11%)

Epoch 2 Summary:
  Train - Loss: 3.2786 (TopK: 3.2712[1.00], CE: 6.9451) | Acc@1: 0.1595
  Val   - Loss: 7.0826 | Acc@1: 0.0000
  Test  - Loss: 7.0815 | Acc@1: 0.0003
  Time: 12.90s | LR: 0.000267
  Params: 440,669

============================================================
Epoch 3/600
============================================================
Epoch 3 | Batch 10/78 | Loss: 2.9978 (TopK: 2.9877, CE: 6.3437) | Acc@1: 0.1979 | Acc@5: 0.3333 | Acc@10: 0.4583 | AccumSteps: 1
Epoch 3 | Batch 20/78 | Loss: 2.9934 (TopK: 2.9832, CE: 6.3820) | Acc@1: 0.1667 | Acc@5: 0.4896 | Acc@10: 0.6042 | AccumSteps: 1
Epoch 3 | Batch 30/78 | Loss: 2.9179 (TopK: 2.9079, CE: 6.2288) | Acc@1: 0.1875 | Acc@5: 0.5000 | Acc@10: 0.5312 | AccumSteps: 1
Epoch 3 | Batch 40/78 | Loss: 2.9047 (TopK: 2.8949, CE: 6.1737) | Acc@1: 0.1875 | Acc@5: 0.5000 | Acc@10: 0.5312 | AccumSteps: 1
Epoch 3 | Batch 50/78 | Loss: 2.7368 (TopK: 2.7275, CE: 5.8532) | Acc@1: 0.2396 | Acc@5: 0.4375 | Acc@10: 0.5521 | AccumSteps: 1
Epoch 3 | Batch 60/78 | Loss: 2.8526 (TopK: 2.8434, CE: 5.9372) | Acc@1: 0.1875 | Acc@5: 0.4375 | Acc@10: 0.4792 | AccumSteps: 1
Epoch 3 | Batch 70/78 | Loss: 2.6869 (TopK: 2.6779, CE: 5.6897) | Acc@1: 0.2083 | Acc@5: 0.4688 | Acc@10: 0.5000 | AccumSteps: 1

Validation Results:
  Loss: 7.0763
  Acc@1: 0.0000 (0.00%)
  Acc@5: 0.0003 (0.03%)
  Acc@10: 0.0009 (0.09%)


Test Results:
  Loss: 7.0763
  Acc@1: 0.0003 (0.03%)
  Acc@5: 0.0006 (0.06%)
  Acc@10: 0.0014 (0.14%)

Epoch 3 Summary:
  Train - Loss: 2.8672 (TopK: 2.8575[1.00], CE: 6.0994) | Acc@1: 0.2006
  Val   - Loss: 7.0763 | Acc@1: 0.0000
  Test  - Loss: 7.0763 | Acc@1: 0.0003
  Time: 12.96s | LR: 0.000400
  Params: 440,669

============================================================
Epoch 4/600
============================================================
Epoch 4 | Batch 10/78 | Loss: 2.2267 (TopK: 2.2155, CE: 5.0233) | Acc@1: 0.3125 | Acc@5: 0.5729 | Acc@10: 0.5938 | AccumSteps: 1
Epoch 4 | Batch 20/78 | Loss: 2.3267 (TopK: 2.3148, CE: 5.2819) | Acc@1: 0.3125 | Acc@5: 0.5938 | Acc@10: 0.6250 | AccumSteps: 1
Epoch 4 | Batch 30/78 | Loss: 2.5600 (TopK: 2.5478, CE: 5.6091) | Acc@1: 0.2188 | Acc@5: 0.4896 | Acc@10: 0.5521 | AccumSteps: 1
Epoch 4 | Batch 40/78 | Loss: 2.8642 (TopK: 2.8509, CE: 6.1939) | Acc@1: 0.1979 | Acc@5: 0.3750 | Acc@10: 0.3958 | AccumSteps: 1
Epoch 4 | Batch 50/78 | Loss: 2.4276 (TopK: 2.4151, CE: 5.5260) | Acc@1: 0.3021 | Acc@5: 0.5208 | Acc@10: 0.6250 | AccumSteps: 1
Epoch 4 | Batch 60/78 | Loss: 2.3555 (TopK: 2.3436, CE: 5.3209) | Acc@1: 0.2188 | Acc@5: 0.5729 | Acc@10: 0.6354 | AccumSteps: 1
Epoch 4 | Batch 70/78 | Loss: 2.3934 (TopK: 2.3809, CE: 5.4875) | Acc@1: 0.2604 | Acc@5: 0.5104 | Acc@10: 0.6146 | AccumSteps: 1

Validation Results:
  Loss: 7.0659
  Acc@1: 0.1312 (13.12%)
  Acc@5: 0.2018 (20.18%)
  Acc@10: 0.2232 (22.32%)


Test Results:
  Loss: 7.0674
  Acc@1: 0.1297 (12.97%)
  Acc@5: 0.1802 (18.02%)
  Acc@10: 0.1918 (19.18%)

Epoch 4 Summary:
  Train - Loss: 2.4784 (TopK: 2.4661[1.00], CE: 5.5381) | Acc@1: 0.2413
  Val   - Loss: 7.0659 | Acc@1: 0.1312
  Test  - Loss: 7.0674 | Acc@1: 0.1297
  Time: 12.88s | LR: 0.000533
  Params: 440,669
  Saved checkpoint: checkpoints/enhanced_hrm_epoch4.pt
  ✅ New best validation accuracy! (13.12%)
  ✅ New best test accuracy! (12.97%)

============================================================
Epoch 5/600
============================================================
Epoch 5 | Batch 10/78 | Loss: 2.5737 (TopK: 2.5572, CE: 5.8684) | Acc@1: 0.2083 | Acc@5: 0.4896 | Acc@10: 0.5417 | AccumSteps: 1
Epoch 5 | Batch 20/78 | Loss: 2.5466 (TopK: 2.5307, CE: 5.7136) | Acc@1: 0.2292 | Acc@5: 0.4479 | Acc@10: 0.5312 | AccumSteps: 1
Epoch 5 | Batch 30/78 | Loss: 2.2545 (TopK: 2.2394, CE: 5.2487) | Acc@1: 0.2396 | Acc@5: 0.5729 | Acc@10: 0.6354 | AccumSteps: 1
Epoch 5 | Batch 40/78 | Loss: 2.2153 (TopK: 2.2017, CE: 4.9067) | Acc@1: 0.2500 | Acc@5: 0.5417 | Acc@10: 0.5833 | AccumSteps: 1
Epoch 5 | Batch 50/78 | Loss: 2.1914 (TopK: 2.1772, CE: 5.0031) | Acc@1: 0.2083 | Acc@5: 0.5729 | Acc@10: 0.6458 | AccumSteps: 1
